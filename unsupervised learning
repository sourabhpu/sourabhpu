# Unsupervised


#import library

import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

#read dataset

import pandas as pd

df = pd.read_csv("C:\\Users\\ACER\\OneDrive\\Desktop\\mcdonalde\\mcdonaldata.csv")

df

	Unnamed: 0 	item 	servesize 	calories 	protien 	totalfat 	satfat 	transfat 	cholestrol 	carbs 	sugar 	addedsugar 	sodium 	menu
0 	0 	McVeggie Burger 	168 	402 	10.24 	13.83 	5.34 	0.16 	2.49 	56.54 	7.90 	4.49 	706.13 	regular
1 	1 	McAloo Tikki Burger 	146 	339 	8.50 	11.31 	4.27 	0.20 	1.47 	5.27 	7.05 	4.07 	545.34 	regular
2 	2 	McSpicy Paneer Burger 	199 	652 	20.29 	39.45 	17.12 	0.18 	21.85 	52.33 	8.35 	5.27 	1074.58 	regular
3 	3 	Spicy Paneer Wrap 	250 	674 	20.96 	39.10 	19.73 	0.26 	40.93 	59.27 	3.50 	1.08 	1087.46 	regular
4 	4 	American Veg Burger 	177 	512 	15.30 	23.45 	10.51 	0.17 	25.24 	56.96 	7.85 	4.76 	1051.24 	regular
... 	... 	... 	... 	... 	... 	... 	... 	... 	... 	... 	... 	... 	... 	...
136 	136 	Tomato Ketchup Sachets 	8 	11.23 	0.08 	23.45 	0.38 	0.25 	0.08 	2.63 	2.33 	1.64 	414.71 	condiments
137 	137 	Maple Syrup 	3 	86.4 	0.00 	0.00 	0.00 	0.40 	0.30 	21.60 	16.20 	5.34 	71.05 	condiments
138 	138 	Cheese Slice 	14 	51.03 	3.06 	3.99 	0.00 	0.00 	13.43 	0.72 	0.54 	0.00 	15.00 	condiments
139 	139 	Sweet Corn 	40 	45.08 	1.47 	1.00 	2.89 	0.01 	2.00 	7.55 	2.54 	0.00 	178.95 	condiments
140 	140 	Mixed Fruit Beverage 	180 	72.25 	0.65 	0.02 	0.22 	0.04 	0.01 	18.00 	16.83 	0.00 	0.04 	condiments

141 rows × 14 columns

#pair graph

​

sns.pairplot(df,hue='menu')

<seaborn.axisgrid.PairGrid at 0x15642e373a0>

corr=df.corr()

sns.heatmap(corr,annot=True)

plt.xticks(rotation=389)

plt.show()

C:\Users\ACER\AppData\Local\Temp\ipykernel_25116\868114087.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  corr=df.corr()

#CLASSIFICTION

#logistic regression/classification

df['menu'].value_counts()

mccafe        48
regular       36
beverage      17
dessert       12
gourmet       11
condiments     9
breakfast      8
Name: menu, dtype: int64

#qualitative into quantitive

from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()

df['menu']=le.fit_transform(df['menu'])

df['menu'].value_counts()

5    48
6    36
0    17
3    12
4    11
2     9
1     8
Name: menu, dtype: int64

df.head()

	Unnamed: 0 	item 	servesize 	calories 	protien 	totalfat 	satfat 	transfat 	cholestrol 	carbs 	sugar 	addedsugar 	sodium 	menu
0 	0 	McVeggie Burger 	168 	402 	10.24 	13.83 	5.34 	0.16 	2.49 	56.54 	7.90 	4.49 	706.13 	6
1 	1 	McAloo Tikki Burger 	146 	339 	8.50 	11.31 	4.27 	0.20 	1.47 	5.27 	7.05 	4.07 	545.34 	6
2 	2 	McSpicy Paneer Burger 	199 	652 	20.29 	39.45 	17.12 	0.18 	21.85 	52.33 	8.35 	5.27 	1074.58 	6
3 	3 	Spicy Paneer Wrap 	250 	674 	20.96 	39.10 	19.73 	0.26 	40.93 	59.27 	3.50 	1.08 	1087.46 	6
4 	4 	American Veg Burger 	177 	512 	15.30 	23.45 	10.51 	0.17 	25.24 	56.96 	7.85 	4.76 	1051.24 	6

df1=df[df['menu']!=4]

df1['menu'].value_counts()

5    48
6    36
0    17
3    12
2     9
1     8
Name: menu, dtype: int64

df1.head()

	Unnamed: 0 	item 	servesize 	calories 	protien 	totalfat 	satfat 	transfat 	cholestrol 	carbs 	sugar 	addedsugar 	sodium 	menu
0 	0 	McVeggie Burger 	168 	402 	10.24 	13.83 	5.34 	0.16 	2.49 	56.54 	7.90 	4.49 	706.13 	6
1 	1 	McAloo Tikki Burger 	146 	339 	8.50 	11.31 	4.27 	0.20 	1.47 	5.27 	7.05 	4.07 	545.34 	6
2 	2 	McSpicy Paneer Burger 	199 	652 	20.29 	39.45 	17.12 	0.18 	21.85 	52.33 	8.35 	5.27 	1074.58 	6
3 	3 	Spicy Paneer Wrap 	250 	674 	20.96 	39.10 	19.73 	0.26 	40.93 	59.27 	3.50 	1.08 	1087.46 	6
4 	4 	American Veg Burger 	177 	512 	15.30 	23.45 	10.51 	0.17 	25.24 	56.96 	7.85 	4.76 	1051.24 	6

#defining x and y

x=df1.iloc[:,2:5] #independent variable,input,feartures

y=df1['menu'] #dependent variable,output,traget,lvl jisli pridiction karvana ho use

# y select karte hai !! 

# ex;- land price increment whre x is land price change in year,and y in price increment 

x.shape,y.shape

((130, 3), (130,))

x.head(),y.head()

(  servesize calories  protien
 0      168       402    10.24
 1      146       339     8.50
 2      199       652    20.29
 3      250       674    20.96
 4      177       512    15.30,
 0    6
 1    6
 2    6
 3    6
 4    6
 Name: menu, dtype: int32)

#split dependent and independent var. 

#split x and y in trained data set and test data set

from sklearn.model_selection  import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.25)

x_train.shape,x_test.shape,y_train.shape,y_test.shape

((97, 3), (33, 3), (97,), (33,))

x_train

	servesize 	calories 	protien
40 	157 	290.42 	22.46
96 	91.79 	100.99 	1.54
1 	146 	339 	8.50
10 	186 	451 	21.46
129 	286.79 	145.16 	1.52
... 	... 	... 	...
116 	394 	151.36 	0.00
118 	299 	129.48 	0.00
128 	286.79 	151.56 	1.52
27 	109 	317 	4.79
121 	299 	99.6 	0.00

97 rows × 3 columns

y_train

40     1
96     3
1      6
10     6
129    0
      ..
116    0
118    0
128    0
27     6
121    0
Name: menu, Length: 97, dtype: int32

#import algorithm /model

from sklearn.linear_model  import LogisticRegression

lr=LogisticRegression()

#train model

​

lr.fit(x_train,y_train)

C:\ProgramData\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

LogisticRegression()

In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.

#model pridication

​

y_pred_lr=lr.predict(x_test)

y_pred_lr

array([0, 5, 6, 5, 5, 0, 5, 6, 2, 6, 3, 5, 6, 6, 6, 5, 5, 2, 5, 5, 5, 5,
       5, 5, 5, 6, 5, 5, 6, 5, 5, 6, 6])

#evaluation

#1. confusion metrics

# 2.classi. report

# 3.accuracy score

#overfitting and under fitting

​

print(lr.score(x_train,y_train))

print(lr.score(x_test,y_test))

0.6701030927835051
0.7575757575757576

from sklearn.metrics  import confusion_matrix,classification_report,accuracy_score

print(confusion_matrix(y_pred_lr,y_test))

print(classification_report(y_pred_lr,y_test))

print(f'model_score-{lr.score(x_test,y_test)}')

print(f'accuracy_score-{accuracy_score(y_pred_lr,y_test)}')

[[ 0  0  0  0  2  0]
 [ 0  0  0  0  0  0]
 [ 0  0  2  0  0  0]
 [ 0  1  0  0  0  0]
 [ 1  0  0  2 15  0]
 [ 0  0  0  2  0  8]]
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         0
           2       1.00      1.00      1.00         2
           3       0.00      0.00      0.00         1
           5       0.88      0.83      0.86        18
           6       1.00      0.80      0.89        10

    accuracy                           0.76        33
   macro avg       0.48      0.44      0.46        33
weighted avg       0.84      0.76      0.80        33

model_score-0.7575757575757576
accuracy_score-0.7575757575757576

C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

#desicion tree classifier

from sklearn.tree import DecisionTreeClassifier

model=DecisionTreeClassifier()

model.fit(x_train,y_train)

y_pred_model=model.predict(x_test)

print(f'Predicted_y{y_pred_model[:5]} Actual_y{y_test.values[:5]}')

print(confusion_matrix(y_pred_model,y_test))

# from sklearn.metrics  import confusion_matrix,classification_report,accuracy_score

print(classification_report(y_pred_model,y_test))

print(accuracy_score(y_pred_model,y_test))

# plt.figure(figsize=(2,1))

'''

print(sns.heatmap(cm,annot=True))

plt.show()

'''

​

​

Predicted_y[5 0 6 5 5] Actual_y[5 0 6 5 5]
[[ 1  0  0  0  0  0]
 [ 0  0  0  0  0  1]
 [ 0  0  0  0  1  0]
 [ 0  1  0  2  0  0]
 [ 0  0  2  0 15  0]
 [ 0  0  0  2  1  7]]
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         1
           3       0.50      0.67      0.57         3
           5       0.88      0.88      0.88        17
           6       0.88      0.70      0.78        10

    accuracy                           0.76        33
   macro avg       0.54      0.54      0.54        33
weighted avg       0.80      0.76      0.77        33

0.7575757575757576

'\nprint(sns.heatmap(cm,annot=True))\nplt.show()\n'

#random forest classifier

from sklearn.ensemble import RandomForestClassifier

model=RandomForestClassifier()

model.fit(x_train,y_train)

y_pred_model=model.predict(x_test)

print(f'Predicted_y{y_pred_model[:5]} Actual_y{y_test.values[:5]}')

print(confusion_matrix(y_pred_model,y_test))

# from sklearn.metrics  import confusion_matrix,classification_report,accuracy_score

print(classification_report(y_pred_model,y_test))

print(accuracy_score(y_pred_model,y_test))

Predicted_y[5 0 6 5 5] Actual_y[5 0 6 5 5]
[[ 1  0  0  0  0  0]
 [ 0  0  0  0  0  1]
 [ 0  0  2  0  0  0]
 [ 0  1  0  3  2  0]
 [ 0  0  0  0 15  0]
 [ 0  0  0  1  0  7]]
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       0.00      0.00      0.00         1
           2       1.00      1.00      1.00         2
           3       0.75      0.50      0.60         6
           5       0.88      1.00      0.94        15
           6       0.88      0.88      0.88         8

    accuracy                           0.85        33
   macro avg       0.75      0.73      0.74        33
weighted avg       0.84      0.85      0.84        33

0.8484848484848485

#K-Nearest neighbors

from sklearn.neighbors import KNeighborsClassifier

model=KNeighborsClassifier()

model.fit(x_train,y_train)

y_pred_model=model.predict(x_test)

print(f'Predicted_y{y_pred_model[:5]} Actual_y{y_test.values[:5]}')

print(confusion_matrix(y_pred_model,y_test))

# from sklearn.metrics  import confusion_matrix,classification_report,accuracy_score

print(classification_report(y_pred_model,y_test))

print(accuracy_score(y_pred_model,y_test))

Predicted_y[5 0 6 5 5] Actual_y[5 0 6 5 5]
[[ 1  0  0  0  2  0]
 [ 0  0  0  0  0  2]
 [ 0  0  2  0  1  0]
 [ 0  1  0  2  1  0]
 [ 0  0  0  0 13  0]
 [ 0  0  0  2  0  6]]
              precision    recall  f1-score   support

           0       1.00      0.33      0.50         3
           1       0.00      0.00      0.00         2
           2       1.00      0.67      0.80         3
           3       0.50      0.50      0.50         4
           5       0.76      1.00      0.87        13
           6       0.75      0.75      0.75         8

    accuracy                           0.73        33
   macro avg       0.67      0.54      0.57        33
weighted avg       0.73      0.73      0.70        33

0.7272727272727273

#Naive Bayes

'''1. gaussian

2.bernoulli

3.multinomial'''

from sklearn.naive_bayes import GaussianNB

model=GaussianNB()

model.fit(x_train,y_train)

y_pred_model=model.predict(x_test)

print(f'Predicted_y{y_pred_model[:5]} Actual_y{y_test.values[:5]}')

print(confusion_matrix(y_pred_model,y_test))

# from sklearn.metrics  import confusion_matrix,classification_report,accuracy_score

print(classification_report(y_pred_model,y_test))

print(accuracy_score(y_pred_model,y_test))

Predicted_y[0 5 3 0 5] Actual_y[5 0 6 5 5]
[[0 0 0 0 6 0]
 [0 0 0 0 0 2]
 [0 0 2 0 1 0]
 [0 1 0 4 1 2]
 [1 0 0 0 9 0]
 [0 0 0 0 0 4]]
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         6
           1       0.00      0.00      0.00         2
           2       1.00      0.67      0.80         3
           3       1.00      0.50      0.67         8
           5       0.53      0.90      0.67        10
           6       0.50      1.00      0.67         4

    accuracy                           0.58        33
   macro avg       0.50      0.51      0.47        33
weighted avg       0.55      0.58      0.52        33

0.5757575757575758

#Bernoulli

from sklearn.naive_bayes import BernoulliNB

model=BernoulliNB()

model.fit(x_train,y_train)

y_pred_model=model.predict(x_test)

print(f'Predicted_y{y_pred_model[:5]} Actual_y{y_test.values[:5]}')

print(confusion_matrix(y_pred_model,y_test))

# from sklearn.metrics  import confusion_matrix,classification_report,accuracy_score

print(classification_report(y_pred_model,y_test))

print(accuracy_score(y_pred_model,y_test))

Predicted_y[5 5 5 5 5] Actual_y[5 0 6 5 5]
[[ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 1  1  2  4 17  8]
 [ 0  0  0  0  0  0]]
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0
           3       0.00      0.00      0.00         0
           5       1.00      0.52      0.68        33
           6       0.00      0.00      0.00         0

    accuracy                           0.52        33
   macro avg       0.17      0.09      0.11        33
weighted avg       1.00      0.52      0.68        33

0.5151515151515151

C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

#Multinomial

from sklearn.naive_bayes import MultinomialNB

model=MultinomialNB()

model.fit(x_train,y_train)

y_pred_model=model.predict(x_test)

print(f'Predicted_y{y_pred_model[:5]} Actual_y{y_test.values[:5]}')

print(confusion_matrix(y_pred_model,y_test))

# from sklearn.metrics  import confusion_matrix,classification_report,accuracy_score

print(classification_report(y_pred_model,y_test))

print(accuracy_score(y_pred_model,y_test))

Predicted_y[0 5 6 0 5] Actual_y[5 0 6 5 5]
[[0 0 0 0 6 0]
 [0 0 0 0 0 4]
 [0 0 0 1 3 0]
 [0 0 0 2 0 0]
 [1 0 1 0 8 0]
 [0 1 1 1 0 4]]
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         6
           1       0.00      0.00      0.00         4
           2       0.00      0.00      0.00         4
           3       0.50      1.00      0.67         2
           5       0.47      0.80      0.59        10
           6       0.50      0.57      0.53         7

    accuracy                           0.42        33
   macro avg       0.25      0.40      0.30        33
weighted avg       0.28      0.42      0.33        33

0.42424242424242425

#Support Vector Machine

#kernal-poly,linear,rbf(radial basic function)

​

from sklearn.svm import SVC

model=SVC()

model.fit(x_train,y_train)

y_pred_model=model.predict(x_test)

print(f'Predicted_y{y_pred_model[:5]} Actual_y{y_test.values[:5]}')

print(confusion_matrix(y_pred_model,y_test))

print(classification_report(y_pred_model,y_test))

print(accuracy_score(y_pred_model,y_test))

Predicted_y[5 5 6 5 5] Actual_y[5 0 6 5 5]
[[ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 0  0  2  0  1  0]
 [ 0  0  0  0  0  0]
 [ 1  0  0  0 15  0]
 [ 0  1  0  4  1  8]]
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.00      0.00      0.00         0
           2       1.00      0.67      0.80         3
           3       0.00      0.00      0.00         0
           5       0.88      0.94      0.91        16
           6       1.00      0.57      0.73        14

    accuracy                           0.76        33
   macro avg       0.48      0.36      0.41        33
weighted avg       0.94      0.76      0.82        33

0.7575757575757576

C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

from sklearn.svm import SVC

model=SVC(kernel='poly',degree=2,C=.1)

model.fit(x_train,y_train)

y_pred_model=model.predict(x_test)

print(f'Predicted_y{y_pred_model[:5]} Actual_y{y_test.values[:5]}')

print(confusion_matrix(y_pred_model,y_test))

print(classification_report(y_pred_model,y_test))

print(accuracy_score(y_pred_model,y_test))

Predicted_y[5 5 6 0 5] Actual_y[5 0 6 5 5]
[[ 0  0  0  0  2  0]
 [ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 1  0  0  0 14  0]
 [ 0  1  2  4  1  8]]

C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0
           3       0.00      0.00      0.00         0
           5       0.82      0.93      0.87        15
           6       1.00      0.50      0.67        16

    accuracy                           0.67        33
   macro avg       0.30      0.24      0.26        33
weighted avg       0.86      0.67      0.72        33

0.6666666666666666

from sklearn.svm import SVC

model=SVC(kernel='poly',degree=2,C=.1)

model.fit(x_train,y_train)

y_pred_model=model.predict(x_test)

print(f'Predicted_y{y_pred_model[:5]} Actual_y{y_test.values[:5]}')

print(confusion_matrix(y_pred_model,y_test))

print(classification_report(y_pred_model,y_test))

print(accuracy_score(y_pred_model,y_test))

Predicted_y[5 5 6 0 5] Actual_y[5 0 6 5 5]
[[ 0  0  0  0  2  0]
 [ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 1  0  0  0 14  0]
 [ 0  1  2  4  1  8]]
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0
           3       0.00      0.00      0.00         0
           5       0.82      0.93      0.87        15
           6       1.00      0.50      0.67        16

    accuracy                           0.67        33
   macro avg       0.30      0.24      0.26        33
weighted avg       0.86      0.67      0.72        33

0.6666666666666666

C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

from sklearn.svm import SVC

model=SVC(kernel='rbf',degree=2,C=.1)

model.fit(x_train,y_train)

y_pred_model=model.predict(x_test)

print(f'Predicted_y{y_pred_model[:5]} Actual_y{y_test.values[:5]}')

print(confusion_matrix(y_pred_model,y_test))

print(classification_report(y_pred_model,y_test))

print(accuracy_score(y_pred_model,y_test))

Predicted_y[5 5 6 5 5] Actual_y[5 0 6 5 5]
[[ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 0  0  0  0  0  0]
 [ 1  0  0  0 17  0]
 [ 0  1  2  4  0  8]]

C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0
           3       0.00      0.00      0.00         0
           5       1.00      0.94      0.97        18
           6       1.00      0.53      0.70        15

    accuracy                           0.76        33
   macro avg       0.33      0.25      0.28        33
weighted avg       1.00      0.76      0.85        33

0.7575757575757576

C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))


#UNsupervised

#K- MEAN clustring

#association

#import library

import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

#read dataset

import pandas as pd

df = pd.read_csv("C:\\Users\\ACER\\OneDrive\\Desktop\\mcdonalde\\mcdonaldata.csv")

df

	Unnamed: 0 	item 	servesize 	calories 	protien 	totalfat 	satfat 	transfat 	cholestrol 	carbs 	sugar 	addedsugar 	sodium 	menu
0 	0 	McVeggie Burger 	168 	402 	10.24 	13.83 	5.34 	0.16 	2.49 	56.54 	7.90 	4.49 	706.13 	regular
1 	1 	McAloo Tikki Burger 	146 	339 	8.50 	11.31 	4.27 	0.20 	1.47 	5.27 	7.05 	4.07 	545.34 	regular
2 	2 	McSpicy Paneer Burger 	199 	652 	20.29 	39.45 	17.12 	0.18 	21.85 	52.33 	8.35 	5.27 	1074.58 	regular
3 	3 	Spicy Paneer Wrap 	250 	674 	20.96 	39.10 	19.73 	0.26 	40.93 	59.27 	3.50 	1.08 	1087.46 	regular
4 	4 	American Veg Burger 	177 	512 	15.30 	23.45 	10.51 	0.17 	25.24 	56.96 	7.85 	4.76 	1051.24 	regular
... 	... 	... 	... 	... 	... 	... 	... 	... 	... 	... 	... 	... 	... 	...
136 	136 	Tomato Ketchup Sachets 	8 	11.23 	0.08 	23.45 	0.38 	0.25 	0.08 	2.63 	2.33 	1.64 	414.71 	condiments
137 	137 	Maple Syrup 	3 	86.4 	0.00 	0.00 	0.00 	0.40 	0.30 	21.60 	16.20 	5.34 	71.05 	condiments
138 	138 	Cheese Slice 	14 	51.03 	3.06 	3.99 	0.00 	0.00 	13.43 	0.72 	0.54 	0.00 	15.00 	condiments
139 	139 	Sweet Corn 	40 	45.08 	1.47 	1.00 	2.89 	0.01 	2.00 	7.55 	2.54 	0.00 	178.95 	condiments
140 	140 	Mixed Fruit Beverage 	180 	72.25 	0.65 	0.02 	0.22 	0.04 	0.01 	18.00 	16.83 	0.00 	0.04 	condiments

141 rows × 14 columns

df.head(2),df['menu'].value_counts()

(   Unnamed: 0                 item servesize calories  protien  totalfat  \
 0           0      McVeggie Burger      168       402    10.24     13.83   
 1           1  McAloo Tikki Burger      146       339     8.50     11.31   
 
    satfat  transfat  cholestrol  carbs  sugar  addedsugar  sodium     menu  
 0    5.34      0.16        2.49  56.54   7.90        4.49  706.13  regular  
 1    4.27      0.20        1.47   5.27   7.05        4.07  545.34  regular  ,
 mccafe        48
 regular       36
 beverage      17
 dessert       12
 gourmet       11
 condiments     9
 breakfast      8
 Name: menu, dtype: int64)

#dataframe convert into numpy array

dfkm=df.values

print(dfkm[:5])

[[0 'McVeggie Burger' '168\xa0' '402' 10.24 13.83 5.34 0.16 2.49 56.54
  7.9 4.49 706.13 'regular']
 [1 'McAloo Tikki Burger' '146\xa0' '339' 8.5 11.31 4.27 0.2 1.47 5.27
  7.05 4.07 545.34 'regular']
 [2 'McSpicy\x99 Paneer Burger' '199\xa0' '652' 20.29 39.45 17.12 0.18
  21.85 52.33 8.35 5.27 1074.58 'regular']
 [3 'Spicy Paneer Wrap' '250\xa0' '674' 20.96 39.1 19.73 0.26 40.93 59.27
  3.5 1.08 1087.46 'regular']
 [4 'American Veg Burger' '177\xa0' '512' 15.3 23.45 10.51 0.17 25.24
  56.96 7.85 4.76 1051.24 'regular']]

df.info()

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 141 entries, 0 to 140
Data columns (total 14 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   Unnamed: 0  141 non-null    int64  
 1   item        141 non-null    object 
 2   servesize   141 non-null    object 
 3   calories    141 non-null    object 
 4   protien     141 non-null    float64
 5   totalfat    141 non-null    float64
 6   satfat      141 non-null    float64
 7   transfat    141 non-null    float64
 8   cholestrol  141 non-null    float64
 9   carbs       141 non-null    float64
 10  sugar       141 non-null    float64
 11  addedsugar  141 non-null    float64
 12  sodium      141 non-null    float64
 13  menu        141 non-null    object 
dtypes: float64(9), int64(1), object(4)
memory usage: 15.5+ KB

x= dfkm[:,4:9]#feature

y=dfkm[:,-1]#target

x[:3],y[:3]

(array([[10.24, 13.83, 5.34, 0.16, 2.49],
        [8.5, 11.31, 4.27, 0.2, 1.47],
        [20.29, 39.45, 17.12, 0.18, 21.85]], dtype=object),
 array(['regular', 'regular', 'regular'], dtype=object))

#K- MEAN clustring

from sklearn import cluster

cluster.KMeans

sklearn.cluster._kmeans.KMeans

#defining cluster from elbow curve method

import matplotlib.pyplot as plt

l=[]

for i in range (1,11):

    km= cluster.KMeans(i)

    km.fit (df.values[:,4:9])

    l.append(km.inertia_)

plt.plot(range(1,11),l[:10])

plt.grid()

plt.show()

​

l

C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(

[390725.4637503545,
 103919.37390376299,
 47628.60643860444,
 33800.99040874576,
 27481.087869924257,
 20765.81020429709,
 16616.969603549776,
 12647.19079855553,
 10439.944042214875,
 9652.962951036325]

k_M=cluster.KMeans(n_clusters=3)

k_M

​

KMeans(n_clusters=3)

In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.

k_m=k_M.fit(x)

k_m

C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
C:\ProgramData\anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(

KMeans(n_clusters=3)

In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.

km_predict=km.labels_

km_predict

array([0, 0, 9, 9, 9, 9, 0, 0, 4, 4, 2, 5, 5, 2, 0, 0, 1, 1, 9, 4, 4, 4,
       2, 4, 7, 9, 0, 0, 0, 0, 0, 0, 6, 6, 0, 2, 4, 4, 1, 2, 8, 1, 4, 6,
       6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 0, 4, 4, 4, 0,
       0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 6,
       6, 6, 0, 0, 6, 0, 6, 0, 6, 6, 0, 0, 0, 0, 6, 0, 2, 2, 9, 5, 5, 3,
       9, 2, 0, 4, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
       6, 6, 6, 6, 0, 6, 0, 6, 6])

center_point=km.cluster_centers_

df.head(2),df['menu'].value_counts()

(   Unnamed: 0                 item servesize calories  protien  totalfat  \
 0           0      McVeggie Burger      168       402    10.24     13.83   
 1           1  McAloo Tikki Burger      146       339     8.50     11.31   
 
    satfat  transfat  cholestrol  carbs  sugar  addedsugar  sodium     menu  
 0    5.34      0.16        2.49  56.54   7.90        4.49  706.13  regular  
 1    4.27      0.20        1.47   5.27   7.05        4.07  545.34  regular  ,
 mccafe        48
 regular       36
 beverage      17
 dessert       12
 gourmet       11
 condiments     9
 breakfast      8
 Name: menu, dtype: int64)

y=km_predict

y

array([0, 0, 9, 9, 9, 9, 0, 0, 4, 4, 2, 5, 5, 2, 0, 0, 1, 1, 9, 4, 4, 4,
       2, 4, 7, 9, 0, 0, 0, 0, 0, 0, 6, 6, 0, 2, 4, 4, 1, 2, 8, 1, 4, 6,
       6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 0, 4, 4, 4, 0,
       0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 6,
       6, 6, 0, 0, 6, 0, 6, 0, 6, 6, 0, 0, 0, 0, 6, 0, 2, 2, 9, 5, 5, 3,
       9, 2, 0, 4, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
       6, 6, 6, 6, 0, 6, 0, 6, 6])

x[:,4]

array([2.49, 1.47, 21.85, 40.93, 25.24, 36.19, 9.45, 5.17, 31.17, 32.83,
       66.04, 87.63, 81.49, 47.63, 1.51, 8.74, 213.09, 213.09, 31.32,
       31.11, 24.66, 36.99, 55.48, 30.1, 45.15, 6.7, 0.77, 1.09, 1.54,
       0.97, 1.33, 1.84, 0.0, 6.0, 15.96, 78.52, 25.31, 37.75, 212.61,
       53.02, 264.8, 233.3, 28.14, 0.64, 0.27, 6.27, 0.27, 0.48, 0.55,
       21.27, 30.48, 36.55, 25.47, 31.68, 38.95, 29.07, 36.48, 42.55,
       24.43, 29.52, 35.67, 12.27, 22.03, 24.59, 36.67, 14.73, 14.83,
       2.79, 3.3, 4.56, 2.79, 3.3, 4.56, 2.8, 3.3, 0.46, 1.65, 1.57, 1.57,
       12.13, 9.18, 9.42, 9.369, 8.39, 8.39, 9.89, 9.99, 0.4, 0.4, 0.0,
       9.76, 10.89, 4.75, 5.71, 5.85, 8.55, 4.85, 6.55, 6.04, 7.78, 6.19,
       9.23, 4.8, 8.0, 71.23, 48.74, 33.21, 73.11, 110.37, 302.61, 43.68,
       64.19, 8.1, 20.03, 30.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
       0.0, 0.0, 0.0, 0.0, 4.7, 4.7, 4.7, 0.0, 0.0, 0.29, 0.25, 0.1, 0.05,
       0.08, 0.3, 13.43, 2.0, 0.01], dtype=object)

x[y==0,1]#[centroid == regular,protien]

array([13.83, 11.31, 15.08, 11.44, 14.02, 9.32, 10.39, 14.7, 20.77, 7.15,
       9.79, 13.55, 17.28, 4.38, 5.96, 6.32, 4.45, 14.73, 15.01, 18.89,
       7.44, 7.7, 3.63, 3.59, 3.57, 12.77, 7.14, 6.87, 5.45, 7.46, 5.47,
       9.76, 6.81, 24.53, 23.45, 3.99], dtype=object)

plt.figure(figsize=(10,3))

plt.scatter(x[y==0,0],x[y==0,1],s=150,c='red',label= 0)

plt.scatter(x[y==1,0],x[y==1,1],s=150,c='blue',label= 1)

plt.scatter(x[y==2,0],x[y==2,1],s=150,c='green',label= 2)

plt.scatter(x[y==3,0],x[y==3,1],s=150,c='yellow',label= 0)

plt.scatter(x[y==4,0],x[y==4,1],s=150,c='pink',label= 1)

plt.scatter(x[y==5,0],x[y==5,1],s=150,c='indigo',label= 2)

plt.scatter(x[y==6,0],x[y==6,1],s=150,c='orange',label= 2)

plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],s=200,c='black',label='Centrods')

plt.legend()

plt.grid()

plt.show()

​

km.labels_

array([0, 0, 9, 9, 9, 9, 0, 0, 4, 4, 2, 5, 5, 2, 0, 0, 1, 1, 9, 4, 4, 4,
       2, 4, 7, 9, 0, 0, 0, 0, 0, 0, 6, 6, 0, 2, 4, 4, 1, 2, 8, 1, 4, 6,
       6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 0, 4, 4, 4, 0,
       0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 6,
       6, 6, 0, 0, 6, 0, 6, 0, 6, 6, 0, 0, 0, 0, 6, 0, 2, 2, 9, 5, 5, 3,
       9, 2, 0, 4, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
       6, 6, 6, 6, 0, 6, 0, 6, 6])

#hierachical clustring

from sklearn import datasets

from sklearn.cluster import AgglomerativeClustering

from scipy.cluster.hierarchy import dendrogram ,linkage

import matplotlib.pyplot as plt

dfhc=df.values

dfhc[:5]

x=dfhc[:,4:9]

y=dfhc[:,-1]

linkage_matrix = linkage(x,'ward')

plot = plt.figure(figsize=(14,7))

dendrogram(linkage_matrix,color_threshold=0)

plt.title('agglomerative clustering dendogram (linkage=ward)')

plt.xlabel('simple index or (cluster size)')

plt.ylabel('distance')

plt.show()

plt.show()

hc= AgglomerativeClustering(linkage='ward' , n_clusters=3)

hc.fit(x)

hc_labels = hc.labels_

hc_labels

array([2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 0, 0, 0, 0,
       0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 1, 0, 2,
       2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1,
       0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)

plot_2 = plt.figure(figsize=(14,7))

dendrogram (linkage_matrix,truncate_mode='lastp',p=20,leaf_rotation=90.,leaf_font_size=12.,show_contracted=True)

plt.title('agglomerative clustering dendogram (linkage=ward)')

plt.xlabel('simple index or (cluster size)')

plt.ylabel('distance')

plt.show()

#qualitative into quantitive

from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()

df['menu']=le.fit_transform(df['menu'])

df['menu'].value_counts()

​

5    48
6    36
0    17
3    12
4    11
2     9
1     8
Name: menu, dtype: int64

hc.labels_

array([2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 0, 0, 0, 0,
       0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 1, 0, 2,
       2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1,
       0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)

df.values[:,-1]

array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1,
       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,
       4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=object)

df['menu']=df['menu'].replace({6:0,1:1,5:2,3:3,4:4,0:5,2:6})

​

df.values[:,-1]

array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,
       4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
       6, 6, 6, 6, 6, 6, 6, 6, 6], dtype=object)

# df.describe()  # Summary statistics of the dataset

df['menu'].value_counts()  # Count of unique values in the target column

2    48
0    36
5    17
3    12
4    11
6     9
1     8
Name: menu, dtype: int64

# import seaborn as sns

# from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

# true_labels = df.values[:, -1].astype(int)

# cm = confusion_matrix(true_labels, hc.labels_)

# cm=confusion_matrix(df.values[:,-1],hc.labels_)

# print(accuracy_score(df.values[:,-1],hc.labels_))

# print(classification_report(df.values[:,-1],hc.labels_))

# plt.figure(figsize=(2,2))

# sns.heatmap(cm,annot=True)

# plt.xlabel('actual')

# plt.ylabel('predicted')

# plt.show()

# import pandas as pd

# kmp=pd.crosstab(df.values[:,-1],hc.labels_)

# print(kmp)

import seaborn as sns

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

​

true_labels = df.values[:, -1].astype(int)

cm = confusion_matrix(true_labels, hc.labels_)

print(accuracy_score(true_labels, hc.labels_))

print(classification_report(true_labels, hc.labels_))

​

plt.figure(figsize=(2, 2))

sns.heatmap(cm, annot=True)

plt.xlabel('actual')

plt.ylabel('predicted')

plt.show()

​

import pandas as pd

kmp = pd.crosstab(true_labels, hc.labels_)

print(kmp)

0.3829787234042553
              precision    recall  f1-score   support

           0       0.40      0.50      0.44        36
           1       0.50      0.38      0.43         8
           2       0.37      0.69      0.48        48
           3       0.00      0.00      0.00        12
           4       0.00      0.00      0.00        11
           5       0.00      0.00      0.00        17
           6       0.00      0.00      0.00         9

    accuracy                           0.38       141
   macro avg       0.18      0.22      0.19       141
weighted avg       0.26      0.38      0.30       141

C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\ProgramData\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

col_0   0  1   2
row_0           
0      18  2  16
1       4  3   1
2      15  0  33
3       0  0  12
4       8  1   2
5       0  0  17
6       0  0   9

​

​



